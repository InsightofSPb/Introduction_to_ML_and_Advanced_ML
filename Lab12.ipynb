{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjritlDxpMl3Yg1I3mjVnJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InsightofSPb/Introduction_to_ML_and_Advanced_ML/blob/main/Lab12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ygZPwTMyrfb",
        "outputId": "ed01dfa5-0739-49f6-c70c-93910dead95d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ваша карта\n",
            "\n",
            "\u001b[41mS\u001b[0mFFFHH\n",
            "FFFFFF\n",
            "FFFFFF\n",
            "FFFFFF\n",
            "FFFFFH\n",
            "HFHHFG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:13<00:00, 748.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество побед в серии из 10 000 игр:  9116\n",
            "Пять побед подряд впервые было одержано в игре  32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade gym==0.18.0\n",
        "import gym\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epsilon = 0.1 # Параметр эпсилон при использовании эпсилон жадной стратегии\n",
        "gamma = 0.8 # Коэффциент дисконтирования гамма\n",
        "random_seed = 3 #Random seed\n",
        "time_delay = 1 # Задержка времени при отрисовке процесса игры после обучения (секунды)\n",
        "lr_rate = 0.9 #Коэффициент скорости обучения альфа\n",
        "\n",
        "#Создание карты\n",
        "def generate_random_map(size, p, sd):\n",
        "    \"\"\"Generates a random valid map (one that has a path from start to goal)\n",
        "    :param size: size of each side of the grid\n",
        "    :param p: probability that a tile is frozen\n",
        "    \"\"\"\n",
        "    valid = False\n",
        "    np.random.seed(sd)\n",
        "\n",
        "    # DFS to check that it's a valid path.\n",
        "    def is_valid(res):\n",
        "        frontier, discovered = [], set()\n",
        "        frontier.append((0,0))\n",
        "        while frontier:\n",
        "            r, c = frontier.pop()\n",
        "            if not (r,c) in discovered:\n",
        "                discovered.add((r,c))\n",
        "                directions = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n",
        "                for x, y in directions:\n",
        "                    r_new = r + x\n",
        "                    c_new = c + y\n",
        "                    if r_new < 0 or r_new >= size or c_new < 0 or c_new >= size:\n",
        "                        continue\n",
        "                    if res[r_new][c_new] == 'G':\n",
        "                        return True\n",
        "                    if (res[r_new][c_new] not in '#H'):\n",
        "                        frontier.append((r_new, c_new))\n",
        "        return False\n",
        "\n",
        "    while not valid:\n",
        "        p = min(1, p)\n",
        "        res = np.random.choice(['F', 'H'], (size, size), p=[p, 1-p])\n",
        "        res[0][0] = 'S'\n",
        "        res[-1][-1] = 'G'\n",
        "        valid = is_valid(res)\n",
        "    return [\"\".join(x) for x in res]\n",
        "\n",
        "#Генерация карты\n",
        "random_map = generate_random_map(size=6, p=0.8, sd=random_seed) #Создаем свою карту\n",
        "env = gym.make(\"FrozenLake-v0\", desc=random_map, is_slippery=False) #Инициализируем среду\n",
        "print(\"Ваша карта\")\n",
        "env.render() #Выводим карту на экран\n",
        "\n",
        "\n",
        "#Задание алгоритма Q - Обучения\n",
        "def choose_action(state):\n",
        "    action=0\n",
        "    if np.random.uniform(0, 1) < epsilon:\n",
        "        action = np.random.randint(0,env.action_space.n) #***\n",
        "    else:\n",
        "        action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n",
        "    return action\n",
        "# argwhere() ищет индекс элемента по условию, flatten() - возвращает 1D ряд, tolist() - обратная array([])\n",
        "# amax() - максимальное значение вдоль строки\n",
        "def learn(state, state2, reward, action, done):\n",
        "    if done:\n",
        "        Q[state, action] = Q[state, action] + lr_rate * (reward - Q[state, action]) # терминальное состояние\n",
        "    else:\n",
        "        Q[state, action] = Q[state, action] + lr_rate * (reward + gamma * np.max(Q[state2,:]) - Q[state, action])\n",
        "\n",
        "from tqdm import tqdm\n",
        "# Inititalization\n",
        "np.random.seed(random_seed)\n",
        "wins = []\n",
        "total_games = 10000\n",
        "max_steps = 100\n",
        "Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "episode = 0\n",
        "#Main cycle\n",
        "for game in tqdm(range(total_games)):\n",
        "    state = env.reset()\n",
        "    t = 0\n",
        "    while t < max_steps:\n",
        "        if game > 5 and wins[game-5] == 1 and wins[game-4] == 1 and wins[game-3] == 1 and wins[game-2] == 1 and wins[game-1] == 1 and episode == 0:\n",
        "          episode = game\n",
        "        t += 1\n",
        "\n",
        "        action = choose_action(state)\n",
        "\n",
        "        state2, reward, done, info = env.step(action)\n",
        "\n",
        "        if t == max_steps:\n",
        "            done = True  \n",
        "\n",
        "        learn(state, state2, reward, action, done)\n",
        "\n",
        "        state = state2\n",
        "\n",
        "        if done and reward == 1:\n",
        "            wins.append(1)\n",
        "            break\n",
        "        if done:\n",
        "            wins.append(0)\n",
        "            break        \n",
        "\n",
        "\n",
        "print(\"Количество побед в серии из 10 000 игр: \", np.sum(wins))\n",
        "print(\"Пять побед подряд впервые было одержано в игре \", episode)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SGMFZY8w-19k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}